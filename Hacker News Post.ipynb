{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Post \n",
    "\n",
    "In this project, we'll work with a data set of submissions to popular technology site Hacker News.\n",
    "\n",
    "\n",
    "[Here](https://www.kaggle.com/hacker-news/hacker-news-posts) is the data set that we will work for. Below are descriptions of the columns: \n",
    "<ul>\n",
    "<li> `id`: The unique identifier from Hacker News for the post </li> \n",
    "<li> `title`: The title of the post\n",
    "url: The URL that the posts links to, if it the post has a URL </li>\n",
    "<li> `num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "num_comments: The number of comments that were made on the post </li>\n",
    "<li> `author`: The username of the person who submitted the post </li>\n",
    "<li> `created_at`: The date and time at which the post was submitted </li> \n",
    "</ul> \n",
    "\n",
    "We're specifically interested in posts whose titles begin with either `Ask HN` or `Show HN`.\n",
    "We'll compare these two types of posts to determine the following:\n",
    "<ul>\n",
    "<li> Do `Ask HN` or `Show HN` receive more comments on average? </li> \n",
    "<li> Do posts created at a certain time receive more comments on average? </li> \n",
    "</ul> \n",
    "\n",
    "## Introduction\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader \n",
    "opened_file = open(\"hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Headers from a data set\n",
    "We display the first five rows of the data set as above and observe that the first row contains the column headers. In order to analyze our data, we need to first remove the row containing the column headers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "[['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12'], ['10482257', 'Title II kills investment? Comcast and other ISPs are now spending more', 'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/', '53', '22', 'Deinos', '10/31/2015 9:48'], ['10557283', 'Nuts and Bolts Business Advice', '', '3', '4', 'shomberj', '11/13/2015 0:45']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts\n",
    "Now that we've removed the headers from `hn`, we're ready to filter our data. Since we're only concerned with post titles beginning with `Ask HN` or `Show HN`, we'll create new lists of lists containing just the data for those titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17192\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = [] \n",
    "other_posts = []\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title_lower = title.lower()\n",
    "    if title_lower.startswith(\"ask hn\"): \n",
    "        ask_posts.append(row)\n",
    "    elif title_lower.startswith(\"show hn\"): \n",
    "        show_posts.append(row)\n",
    "    else : \n",
    "        other_posts.append(row)\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 1744 rows start with `Ask HN` and 1162 rows start with `Show HN`. \n",
    "\n",
    "## Calculating the Average Number of Comments for Ask HN and Show HN Posts \n",
    "Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0 \n",
    "for row in ask_posts: \n",
    "    num_com = int(row[4]) \n",
    "    total_ask_comments += num_com \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0 \n",
    "for row in show_posts: \n",
    "    num_com = int(row[4]) \n",
    "    total_show_comments += num_com \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the average number of comments for ask posts is about 14 while the average number of comments for show posts is only more than 10. \n",
    "So the ask posts received more comments on average. \n",
    "\n",
    "## Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "<ul>\n",
    "<li> Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.</li> \n",
    "<li> Calculate the average number of comments ask posts receive by hour created.</li> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt \n",
    "result_list = [] \n",
    "for row in ask_posts: \n",
    "    result_list.append([row[6],int(row[4])])\n",
    "counts_by_hour = {} \n",
    "comments_by_hour = {} \n",
    "for row in result_list: \n",
    "    date = row[0]\n",
    "    date_dt = dt.datetime.strptime(date,\"%m/%d/%Y %H:%M\")\n",
    "    hour = date_dt.strftime(\"%H\")\n",
    "    if hour not in counts_by_hour: \n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else: \n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN Posts by Hour\n",
    "We created two dictionaries as above:\n",
    "<ul> \n",
    "<li> `counts_by_hour`: contains the number of ask posts created during each hour of the day. </li> \n",
    "<li> `comments_by_hour` : contains the corresponding number of comments ask posts created at each hour received. </li> \n",
    "</ul> \n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day.\n",
    "\n",
    "We will create a list of list in which the first element is the hour and the second element is the average number of comments per post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['20', 21.525],\n",
       " ['21', 16.009174311926607],\n",
       " ['15', 38.5948275862069],\n",
       " ['23', 7.985294117647059],\n",
       " ['08', 10.25],\n",
       " ['12', 9.41095890410959],\n",
       " ['18', 13.20183486238532],\n",
       " ['16', 16.796296296296298],\n",
       " ['02', 23.810344827586206],\n",
       " ['13', 14.741176470588234],\n",
       " ['14', 13.233644859813085],\n",
       " ['01', 11.383333333333333],\n",
       " ['07', 7.852941176470588],\n",
       " ['19', 10.8],\n",
       " ['05', 10.08695652173913],\n",
       " ['09', 5.5777777777777775],\n",
       " ['22', 6.746478873239437],\n",
       " ['17', 11.46],\n",
       " ['06', 9.022727272727273],\n",
       " ['10', 13.440677966101696],\n",
       " ['11', 11.051724137931034],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['03', 7.796296296296297]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = [] \n",
    "for hour in comments_by_hour: \n",
    "    num = counts_by_hour[hour]\n",
    "    num_com = comments_by_hour[hour]\n",
    "    avg_by_hour.append([hour, num_com/num])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Printing Values from a List of Lists \n",
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours receive the most comments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['15:00: 38.59 average comments per post',\n",
       " '02:00: 23.81 average comments per post',\n",
       " '20:00: 21.52 average comments per post',\n",
       " '16:00: 16.80 average comments per post',\n",
       " '21:00: 16.01 average comments per post']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = [] \n",
    "for row in avg_by_hour: \n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse = True)\n",
    "top_five = []\n",
    "for i in range(5): \n",
    "    hour = sorted_swap[i][1]\n",
    "    hour_dt = dt.datetime.strptime(hour,\"%H\")\n",
    "    hour_fm = hour_dt.strftime(\"%H:%M\")\n",
    "    num = sorted_swap[i][0]\n",
    "    output = \"{hour}: {number:.2f} average comments per post\".format(hour = hour_fm, number = num)\n",
    "    top_five.append(output)\n",
    "print(\"Top 5 Hours receive the most comments\")\n",
    "top_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour that receives most comments is `15:00` with 38.59 comments on average. \n",
    "\n",
    "According to the data set documentation, the timezone used is Eastern Time in the US. So, we could also write 15:00 as 3:00 pm est. Converting to my local time, it is 3:00 am GMT+7. \n",
    "\n",
    "## Conclusion \n",
    "In this project, by analyzing the data set of Hacker News Posts, we observed that there are more comments on average for the ask posts than for the show post. After that, we calculated the amount of ask posts and comments by hour created and found that posts created at 3:00 pm EST (3:00 AM GMT+7) has the highest number of comments. \n",
    "\n",
    "So we recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
